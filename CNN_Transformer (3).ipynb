{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "cS9JGkcmtq_f"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "import numpy as np\n",
        "import math\n",
        "from sklearn.metrics import r2_score\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ──────────────────────────────────────────────────────────────────────────────\n",
        "# 1) 데이터셋 로드 & 분할\n",
        "# ──────────────────────────────────────────────────────────────────────────────\n",
        "raw = torch.load('/content/drive/MyDrive/DEAM_dataset_cleaned.pt')\n",
        "\n",
        "# dict with keys 'spectrograms', 'annotations', 'song_ids'\n",
        "clean_specs = raw['spectrograms']   # Tensor list or Tensor of shape (N,1,128,60)\n",
        "clean_anns  = raw['annotations']    # Tensor list or Tensor of shape (N,60,2)\n",
        "clean_ids   = raw['song_ids']       # list or Tensor of shape (N,)\n",
        "\n",
        "# make sure they're all the same length N\n",
        "N = len(clean_ids)\n",
        "\n",
        "# build unified list of dicts\n",
        "data_list = []\n",
        "for i in range(N):\n",
        "    song_id = int(clean_ids[i])\n",
        "\n",
        "    spec    = clean_specs[i]   # Tensor[1,128,60]\n",
        "    ann     = clean_anns[i]    # Tensor[60,2]\n",
        "    data_list.append({'song_id': song_id, 'spec': spec, 'ann': ann})\n"
      ],
      "metadata": {
        "id": "rGFjsLoSu72r"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ──────────────────────────────────────────────────────────────────────────────\n",
        "# 2) Train/Val/Test 데이터 분할 (정규화 포함)\n",
        "# ──────────────────────────────────────────────────────────────────────────────\n",
        "\n",
        "# Step 1: song_id를 기준으로 데이터 아이템을 train/val과 test용으로 먼저 분리합니다.\n",
        "train_val_ids = {d['song_id'] for d in data_list if d['song_id'] <= 2000}\n",
        "test_ids      = {d['song_id'] for d in data_list if d['song_id']  > 2000}\n",
        "\n",
        "train_val_items = [d for d in data_list if d['song_id'] in train_val_ids]\n",
        "test_items      = [d for d in data_list if d['song_id'] in test_ids]\n",
        "\n",
        "# Step 2: train_val_items를 train과 validation용으로 다시 분할합니다.\n",
        "#         random_split을 사용하기 위해 임시 Dataset을 만듭니다.\n",
        "class TempDataset(Dataset):\n",
        "    def __init__(self, items): self.items = items\n",
        "    def __len__(self): return len(self.items)\n",
        "    def __getitem__(self, idx): return self.items[idx]\n",
        "\n",
        "val_ratio = 0.1\n",
        "temp_ds = TempDataset(train_val_items)\n",
        "val_size = int(len(temp_ds) * val_ratio)\n",
        "train_size = len(temp_ds) - val_size\n",
        "\n",
        "train_subset, val_subset = random_split(\n",
        "    temp_ds, [train_size, val_size], generator=torch.Generator().manual_seed(42)\n",
        ")\n",
        "\n",
        "# 분할된 subset에서 실제 데이터 아이템 리스트를 다시 추출합니다.\n",
        "train_items = [item for item in train_subset]\n",
        "val_items   = [item for item in val_subset]\n",
        "\n",
        "\n",
        "# Step 3: ★★★ 오직 Train 데이터셋의 스펙트로그램으로만 평균과 표준편차를 계산합니다. ★★★\n",
        "print(\"학습 데이터셋에서 정규화 통계치 계산 중...\")\n",
        "train_specs = torch.cat([d['spec'] for d in train_items], dim=0) # 모든 스펙트로그램을 배치 차원으로 연결\n",
        "mean = train_specs.mean()\n",
        "std = train_specs.std()\n",
        "\n",
        "print(f\"  - 계산된 Mean: {mean:.4f}\")\n",
        "print(f\"  - 계산된 Std Dev: {std:.4f}\")\n",
        "# 이 값을 저장해두면 나중에 추론 시에도 사용할 수 있습니다.\n",
        "torch.save({'mean': mean, 'std': std}, 'norm_stats.pt')\n",
        "\n",
        "\n",
        "# Step 4: 계산된 통계치(mean, std)를 모든 데이터에 적용합니다.\n",
        "#         (메모리 절약을 위해 in-place로 연산)\n",
        "def normalize_items(items, mean, std):\n",
        "    for item in items:\n",
        "        item['spec'] = (item['spec'] - mean) / (std + 1e-8) # 0으로 나누는 것을 방지\n",
        "    return items\n",
        "\n",
        "train_items = normalize_items(train_items, mean, std)\n",
        "val_items   = normalize_items(val_items, mean, std)\n",
        "test_items  = normalize_items(test_items, mean, std)\n",
        "print(\"모든 데이터셋(Train/Val/Test)에 정규화를 적용했습니다.\")\n",
        "\n",
        "\n",
        "# Step 5: 최종 PyTorch Dataset을 생성합니다.\n",
        "class DEAMDataset(Dataset):\n",
        "    def __init__(self, items):\n",
        "        self.samples = items\n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n",
        "    def __getitem__(self, idx):\n",
        "        # 데이터가 이미 정규화되었으므로 그대로 반환\n",
        "        return self.samples[idx]['spec'], self.samples[idx]['ann']\n",
        "\n",
        "train_ds = DEAMDataset(train_items)\n",
        "val_ds   = DEAMDataset(val_items)\n",
        "test_ds  = DEAMDataset(test_items)\n",
        "\n",
        "print(f\"\\n데이터셋 준비 완료:\")\n",
        "print(f\"  - Train: {len(train_ds)} 샘플\")\n",
        "print(f\"  - Validation: {len(val_ds)} 샘플\")\n",
        "print(f\"  - Test: {len(test_ds)} 샘플\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VUb14rFjCoHu",
        "outputId": "8ec15077-d5af-4004-8ddb-23873e7e2ae8"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "학습 데이터셋에서 정규화 통계치 계산 중...\n",
            "  - 계산된 Mean: -0.0000\n",
            "  - 계산된 Std Dev: 1.0000\n",
            "모든 데이터셋(Train/Val/Test)에 정규화를 적용했습니다.\n",
            "\n",
            "데이터셋 준비 완료:\n",
            "  - Train: 1570 샘플\n",
            "  - Validation: 174 샘플\n",
            "  - Test: 58 샘플\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ──────────────────────────────────────────────────────────────────────────────\n",
        "# 3) DataLoader\n",
        "# ──────────────────────────────────────────────────────────────────────────────\n",
        "batch_size  = 16\n",
        "num_workers = 2\n",
        "\n",
        "train_loader = DataLoader(train_ds,   batch_size=batch_size, shuffle=True,  num_workers=num_workers)\n",
        "val_loader   = DataLoader(val_ds,     batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
        "test_loader  = DataLoader(test_ds,    batch_size=batch_size, shuffle=False, num_workers=num_workers)\n"
      ],
      "metadata": {
        "id": "y0GcpT9svDDz"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def safe_collate(batch):\n",
        "    # batch: list of (spec,ann)\n",
        "    specs, anns = zip(*batch)\n",
        "    # 각 원소를 반드시 clone() 하여 독립 스토리지 확보\n",
        "    specs = [torch.as_tensor(s, dtype=torch.float32).clone() for s in specs]\n",
        "    anns  = [torch.as_tensor(a, dtype=torch.float32).clone() for a in anns]\n",
        "    return torch.stack(specs, 0), torch.stack(anns, 0)\n",
        "\n",
        "train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True,\n",
        "                          num_workers=4, collate_fn=safe_collate)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QSbT7Umhogz9",
        "outputId": "9859f26b-f1d2-4247-fbb7-e4f5276b8bde"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ──────────────────────────────────────────────────────────────────────────────\n",
        "# 1) Concordance Correlation Coefficient 정의\n",
        "# ──────────────────────────────────────────────────────────────────────────────\n",
        "def concordance_correlation_coefficient(y_true: np.ndarray, y_pred: np.ndarray) -> float:\n",
        "    true_mean = np.mean(y_true)\n",
        "    pred_mean = np.mean(y_pred)\n",
        "    covariance = np.mean((y_true - true_mean) * (y_pred - pred_mean))\n",
        "    true_var = np.var(y_true)\n",
        "    pred_var = np.var(y_pred)\n",
        "    return 2 * covariance / (true_var + pred_var + (true_mean - pred_mean)**2 + 1e-8)"
      ],
      "metadata": {
        "id": "f1zC2Wzoxmf0"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ──────────────────────────────────────────────────────────────────────────────\n",
        "# 4) 모델 정의 (CNN + Transformer)\n",
        "# ──────────────────────────────────────────────────────────────────────────────\n",
        "class DetailedEmotionCNN(nn.Module):\n",
        "    def __init__(self, dropout_cfg=(0.3,0.3,0.4,0.4), negative_slope=0.02):\n",
        "        super().__init__()\n",
        "        d1,d2,d3,d4 = dropout_cfg\n",
        "        nl = negative_slope\n",
        "\n",
        "        # Block1\n",
        "        self.block1 = nn.Sequential(\n",
        "            nn.Conv2d(1,16,3,padding=1), nn.BatchNorm2d(16),\n",
        "            nn.LeakyReLU(nl,inplace=True),\n",
        "            nn.Conv2d(16,16,3,padding=1), nn.BatchNorm2d(16),\n",
        "            nn.LeakyReLU(nl,inplace=True),\n",
        "            nn.Dropout(d1),\n",
        "            nn.MaxPool2d((2,1),stride=(2,1)),\n",
        "        )\n",
        "        # Block2\n",
        "        self.block2 = nn.Sequential(\n",
        "            nn.Conv2d(16,32,3,padding=1), nn.BatchNorm2d(32),\n",
        "            nn.LeakyReLU(nl,inplace=True),\n",
        "            nn.Conv2d(32,32,3,padding=1), nn.BatchNorm2d(32),\n",
        "            nn.LeakyReLU(nl,inplace=True),\n",
        "            nn.Dropout(d2),\n",
        "            nn.MaxPool2d((2,1),stride=(2,1)),\n",
        "        )\n",
        "        # Block3\n",
        "        self.block3 = nn.Sequential(\n",
        "            nn.Conv2d(32,64,3,padding=1), nn.BatchNorm2d(64),\n",
        "            nn.LeakyReLU(nl,inplace=True),\n",
        "            nn.Conv2d(64,64,3,padding=1), nn.BatchNorm2d(64),\n",
        "            nn.LeakyReLU(nl,inplace=True),\n",
        "            nn.Dropout(d3),\n",
        "            nn.MaxPool2d((2,1),stride=(2,1)),\n",
        "        )\n",
        "        # Block4 + extra conv+pool\n",
        "        self.block4 = nn.Sequential(\n",
        "            nn.Conv2d(64,128,3,padding=1), nn.BatchNorm2d(128),\n",
        "            nn.LeakyReLU(nl,inplace=True),\n",
        "            nn.Conv2d(128,128,3,padding=1), nn.BatchNorm2d(128),\n",
        "            nn.LeakyReLU(nl,inplace=True),\n",
        "            nn.Dropout(d4),\n",
        "            nn.MaxPool2d((2,1),stride=(2,1)),\n",
        "            nn.Conv2d(128,128,3,padding=1), nn.BatchNorm2d(128),\n",
        "            nn.LeakyReLU(nl,inplace=True),\n",
        "            nn.MaxPool2d((8,1),stride=(8,1)),\n",
        "        )\n",
        "        # 마지막 채널 2개로\n",
        "        self.conv_out = nn.Conv2d(128,2,1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x: [B,1,128,60]\n",
        "        x = self.block1(x)   # → [B,16,64,60]\n",
        "        x = self.block2(x)   # → [B,32,32,60]\n",
        "        x = self.block3(x)   # → [B,64,16,60]\n",
        "        x = self.block4(x)   # → [B,128,1,60]\n",
        "        x = self.conv_out(x) # → [B,2,1,60]\n",
        "        x = x.squeeze(2)     # → [B,2,60]\n",
        "        return x.permute(0,2,1)  # → [B,60,2]  (valence/arousal)\n",
        "\n",
        "\n",
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, d_model: int, max_len: int = 5000):\n",
        "        super().__init__()\n",
        "        pe = torch.zeros(max_len, d_model)\n",
        "        pos = torch.arange(0,max_len).unsqueeze(1).float()\n",
        "        div = torch.exp(torch.arange(0,d_model,2).float() * (-math.log(10000.0)/d_model))\n",
        "        pe[:,0::2] = torch.sin(pos*div)\n",
        "        pe[:,1::2] = torch.cos(pos*div)\n",
        "        self.register_buffer('pe', pe.unsqueeze(0))\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x: [B,T,d_model]\n",
        "        return x + self.pe[:,:x.size(1),:]\n",
        "\n",
        "\n",
        "class CNNTransformerEmotion(nn.Module):\n",
        "    def __init__(self,\n",
        "                 cnn: nn.Module,\n",
        "                 d_model: int = 128,\n",
        "                 nhead: int = 8,\n",
        "                 num_layers: int = 4,\n",
        "                 dim_feedforward: int = 512,\n",
        "                 dropout: float = 0.1,\n",
        "                 seq_len: int = 60):\n",
        "        super().__init__()\n",
        "        self.cnn = cnn\n",
        "        # CNN에서 2채널 → d_model로 매핑\n",
        "        self.channel_mapper = nn.Conv2d(2, d_model, 1)\n",
        "        self.pos_encoder   = PositionalEncoding(d_model, max_len=seq_len)\n",
        "        enc_layer = nn.TransformerEncoderLayer(\n",
        "            d_model=d_model, nhead=nhead,\n",
        "            dim_feedforward=dim_feedforward,\n",
        "            dropout=dropout, activation='relu'\n",
        "        )\n",
        "        self.transformer = nn.TransformerEncoder(enc_layer, num_layers=num_layers)\n",
        "        self.regressor   = nn.Linear(d_model, 2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x: [B,1,128,60]\n",
        "        feat = self.cnn(x)          # → [B,60,2]\n",
        "        feat = feat.permute(0,2,1).unsqueeze(-1)   # → [B,2,60,1]\n",
        "        feat = self.channel_mapper(feat)           # → [B,d_model,60,1]\n",
        "        seq  = feat.squeeze(-1).permute(0,2,1)     # → [B,60,d_model]\n",
        "        seq  = self.pos_encoder(seq)               # → [B,60,d_model]\n",
        "        seq  = self.transformer(seq)               # → [B,60,d_model]\n",
        "        return torch.tanh(self.regressor(seq))     # → [B,60,2]"
      ],
      "metadata": {
        "id": "1-1gHSFbus01"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# device 설정\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "fovMyjiWxtnz"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 인스턴스\n",
        "base_cnn = DetailedEmotionCNN()\n",
        "model    = CNNTransformerEmotion(base_cnn).to(device)\n",
        "\n",
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "trainable   = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print(f\"Total: {total_params:,}개, Trainable: {trainable:,}개\")\n",
        "\n",
        "\n",
        "# ──────────────────────────────────────────────────────────────────────────────\n",
        "# 5) Optimizer / Scheduler / Loss 설정\n",
        "# ──────────────────────────────────────────────────────────────────────────────\n",
        "lr, weight_decay = 1e-3, 1e-5\n",
        "optimizer   = optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "scheduler   = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=4, factor=0.5)\n",
        "criterion   = nn.MSELoss()\n",
        "early_stop_patience = 5\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n-GeB73ayNgK",
        "outputId": "0b5529a9-c77d-4cb2-f3c5-d96a00e669aa"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total: 1,236,020개, Trainable: 1,236,020개\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ──────────────────────────────────────────────────────────────────────────────\n",
        "# 6) TRAIN / VAL / TEST 루프\n",
        "# ──────────────────────────────────────────────────────────────────────────────\n",
        "best_val_loss      = float('inf')\n",
        "early_stop_counter = 0\n",
        "\n",
        "for epoch in range(1, 51):\n",
        "    # -- TRAIN --\n",
        "    model.train()\n",
        "    train_loss = 0.0\n",
        "    for spec, ann in train_loader:\n",
        "        spec, ann = spec.to(device), ann.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        out = model(spec)        # [B,60,2]\n",
        "        loss = criterion(out, ann)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        train_loss += loss.item() * spec.size(0)\n",
        "    train_loss /= len(train_loader.dataset)\n",
        "\n",
        "    # -- VALIDATION --\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    all_preds, all_trues = [], []\n",
        "    with torch.no_grad():\n",
        "        for spec, ann in val_loader:\n",
        "            spec, ann = spec.to(device), ann.to(device)\n",
        "            out = model(spec)\n",
        "            val_loss += criterion(out, ann).item() * spec.size(0)\n",
        "            all_preds.append(out.cpu().numpy().reshape(-1,2))\n",
        "            all_trues.append(ann.cpu().numpy().reshape(-1,2))\n",
        "    val_loss /= len(val_loader.dataset)\n",
        "\n",
        "    preds = np.vstack(all_preds)\n",
        "    trues = np.vstack(all_trues)\n",
        "    # 지표 계산\n",
        "    mse     = np.mean((preds-trues)**2)\n",
        "    mae     = np.mean(np.abs(preds-trues))\n",
        "    r_val   = np.corrcoef(trues[:,0],preds[:,0])[0,1]\n",
        "    r_aro   = np.corrcoef(trues[:,1],preds[:,1])[0,1]\n",
        "    r2_val  = r2_score(trues[:,0],preds[:,0])\n",
        "    r2_aro  = r2_score(trues[:,1],preds[:,1])\n",
        "    ccc_val = concordance_correlation_coefficient(trues[:,0],preds[:,0])\n",
        "    ccc_aro = concordance_correlation_coefficient(trues[:,1],preds[:,1])\n",
        "\n",
        "    # Scheduler & EarlyStopping\n",
        "    scheduler.step(val_loss)\n",
        "    if val_loss < best_val_loss:\n",
        "        best_val_loss, best_epoch = val_loss, epoch\n",
        "        early_stop_counter = 0\n",
        "        torch.save(model.state_dict(), 'best_model.pt')\n",
        "    else:\n",
        "        early_stop_counter += 1\n",
        "\n",
        "    lr_current = optimizer.param_groups[0]['lr']\n",
        "    print(f\"[{epoch:02d}] Train:{train_loss:.4f} | Val:{val_loss:.4f} | LR:{lr_current:.2e}\")\n",
        "    print(f\"    MSE:{mse:.4f}, MAE:{mae:.4f}, Corr(V/A):{r_val:.4f}/{r_aro:.4f}, \"\n",
        "          f\"R2(V/A):{r2_val:.4f}/{r2_aro:.4f}, CCC(V/A):{ccc_val:.4f}/{ccc_aro:.4f}\")\n",
        "\n",
        "    if early_stop_counter >= early_stop_patience:\n",
        "        print(f\"Early stopping @ epoch {epoch} (Best Val {best_val_loss:.4f} @ {best_epoch})\")\n",
        "        break\n",
        "\n",
        "print(f\"\\n== Training completed. Best Val Loss: {best_val_loss:.4f} @ epoch {best_epoch} ==\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zxRUkF1KvsQN",
        "outputId": "06354324-6ef8-4d7b-d7d9-16be71af1a8f"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[01] Train:0.1892 | Val:0.0624 | LR:1.00e-03\n",
            "    MSE:0.0624, MAE:0.2019, Corr(V/A):0.3813/0.7358, R2(V/A):0.0612/0.1688, CCC(V/A):0.0809/0.3137\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[02] Train:0.0528 | Val:0.0547 | LR:1.00e-03\n",
            "    MSE:0.0547, MAE:0.1863, Corr(V/A):0.4041/0.7232, R2(V/A):0.1283/0.3081, CCC(V/A):0.1704/0.4579\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[03] Train:0.0519 | Val:0.0612 | LR:1.00e-03\n",
            "    MSE:0.0612, MAE:0.1905, Corr(V/A):0.4241/0.7502, R2(V/A):0.0240/0.2267, CCC(V/A):0.2203/0.5306\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[04] Train:0.0497 | Val:0.0440 | LR:1.00e-03\n",
            "    MSE:0.0440, MAE:0.1681, Corr(V/A):0.4135/0.7707, R2(V/A):0.1657/0.5435, CCC(V/A):0.2597/0.6701\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[05] Train:0.0480 | Val:0.0519 | LR:1.00e-03\n",
            "    MSE:0.0519, MAE:0.1820, Corr(V/A):0.4208/0.7462, R2(V/A):0.0478/0.4367, CCC(V/A):0.1534/0.5265\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06] Train:0.0470 | Val:0.0494 | LR:1.00e-03\n",
            "    MSE:0.0494, MAE:0.1768, Corr(V/A):0.4064/0.7420, R2(V/A):0.0683/0.4838, CCC(V/A):0.1595/0.5886\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[07] Train:0.0451 | Val:0.0524 | LR:1.00e-03\n",
            "    MSE:0.0524, MAE:0.1822, Corr(V/A):0.4340/0.7334, R2(V/A):0.1614/0.3403, CCC(V/A):0.2195/0.5088\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[08] Train:0.0438 | Val:0.0475 | LR:1.00e-03\n",
            "    MSE:0.0475, MAE:0.1801, Corr(V/A):0.4320/0.7667, R2(V/A):0.0820/0.5203, CCC(V/A):0.1773/0.6499\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[09] Train:0.0437 | Val:0.0490 | LR:5.00e-04\n",
            "    MSE:0.0490, MAE:0.1716, Corr(V/A):0.4043/0.7525, R2(V/A):0.1208/0.4554, CCC(V/A):0.3038/0.6301\n",
            "Early stopping @ epoch 9 (Best Val 0.0440 @ 4)\n",
            "\n",
            "== Training completed. Best Val Loss: 0.0440 @ epoch 4 ==\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# -- TEST --\n",
        "model.load_state_dict(torch.load('best_model.pt'))\n",
        "model.eval()\n",
        "all_preds, all_trues = [], []\n",
        "with torch.no_grad():\n",
        "    for spec, ann in test_loader:\n",
        "        spec, ann = spec.to(device), ann.to(device)\n",
        "        out = model(spec)\n",
        "        all_preds.append(out.cpu().numpy().reshape(-1,2))\n",
        "        all_trues.append(ann.cpu().numpy().reshape(-1,2))\n",
        "preds = np.vstack(all_preds)\n",
        "trues = np.vstack(all_trues)\n",
        "\n",
        "# 테스트 지표 출력\n",
        "print(\"\\n== Test Results ==\")\n",
        "print(f\"MSE: {np.mean((preds-trues)**2):.4f}, MAE: {np.mean(np.abs(preds-trues)):.4f}\")\n",
        "print(f\"Corr(V): {np.corrcoef(trues[:,0],preds[:,0])[0,1]:.4f}, Corr(A): {np.corrcoef(trues[:,1],preds[:,1])[0,1]:.4f}\")\n",
        "print(f\"R2(V/A): {r2_score(trues[:,0],preds[:,0]):.4f}/{r2_score(trues[:,1],preds[:,1]):.4f}\")\n",
        "print(f\"CCC(V/A): {concordance_correlation_coefficient(trues[:,0],preds[:,0]):.4f}/\"\n",
        "      f\"{concordance_correlation_coefficient(trues[:,1],preds[:,1]):.4f}\")"
      ],
      "metadata": {
        "id": "nplqQ80nyQOw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "# 이전에 정의된 concordance_correlation_coefficient 함수가 필요합니다.\n",
        "def concordance_correlation_coefficient(y_true: np.ndarray, y_pred: np.ndarray) -> float:\n",
        "    true_mean = np.mean(y_true)\n",
        "    pred_mean = np.mean(y_pred)\n",
        "    covariance = np.mean((y_true - true_mean) * (y_pred - pred_mean))\n",
        "    true_var = np.var(y_true)\n",
        "    pred_var = np.var(y_pred)\n",
        "    return 2 * covariance / (true_var + pred_var + (true_mean - pred_mean)**2 + 1e-8)\n",
        "\n",
        "\n",
        "# ──────────────────────────────────────────────────────────────────────────────\n",
        "# 1) 모델 로드 및 평가 준비\n",
        "# ──────────────────────────────────────────────────────────────────────────────\n",
        "model.load_state_dict(torch.load('best_model.pt'))\n",
        "model.eval()\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "all_song_preds = []\n",
        "all_song_trues = []\n",
        "\n",
        "print(\"곡 단위 테스트 데이터 예측을 시작합니다...\")\n",
        "\n",
        "# ──────────────────────────────────────────────────────────────────────────────\n",
        "# 2) DataLoader 대신 test_items 리스트를 직접 순회하며 곡 단위로 예측\n",
        "# ──────────────────────────────────────────────────────────────────────────────\n",
        "for song_data in test_items:\n",
        "    # ★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★\n",
        "    # [수정된 부분 1]\n",
        "    # .squeeze(0)를 제거하여 채널 차원을 보존합니다.\n",
        "    # spec_tensor의 모양은 [1, 128, T_variable]가 됩니다. (1이 채널 차원)\n",
        "    # ★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★\n",
        "    spec_tensor = song_data['spec']\n",
        "    ann_tensor = song_data['ann']\n",
        "\n",
        "    T = spec_tensor.shape[-1]\n",
        "    windows = []\n",
        "    for start in range(0, T, 60):\n",
        "        # ★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★\n",
        "        # [수정된 부분 2]\n",
        "        # 3D 텐서를 슬라이싱하므로 win의 모양은 [1, 128, 60]이 됩니다.\n",
        "        # ★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★\n",
        "        win = spec_tensor[:, :, start:start+60]\n",
        "\n",
        "        if win.size(-1) < 60:\n",
        "            pad_size = 60 - win.size(-1)\n",
        "            win = torch.nn.functional.pad(win, (0, pad_size), \"constant\", 0)\n",
        "\n",
        "        windows.append(win)\n",
        "\n",
        "    if not windows:\n",
        "        continue\n",
        "\n",
        "    # ★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★\n",
        "    # [수정된 부분 3]\n",
        "    # `windows` 리스트에는 [1, 128, 60] 모양의 3D 텐서들이 들어있습니다.\n",
        "    # torch.cat으로 dim=0에 대해 합치면 [num_windows, 1, 128, 60] 모양의\n",
        "    # 올바른 4D 텐서가 됩니다.\n",
        "    # ★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★\n",
        "    batch = torch.cat(windows, dim=0).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        out = model(batch)\n",
        "\n",
        "    preds_padded = out.cpu().numpy().reshape(-1, 2)\n",
        "    preds_song = preds_padded[:T]\n",
        "\n",
        "    all_song_preds.append(preds_song)\n",
        "    all_song_trues.append(ann_tensor.cpu().numpy())\n",
        "\n",
        "\n",
        "# ──────────────────────────────────────────────────────────────────────────────\n",
        "# 3) 전체 테스트셋에 대한 평가 지표 계산 및 출력 (이전과 동일)\n",
        "# ──────────────────────────────────────────────────────────────────────────────\n",
        "if all_song_preds:\n",
        "    preds_flat = np.vstack(all_song_preds)\n",
        "    trues_flat = np.vstack(all_song_trues)\n",
        "\n",
        "    mse = np.mean((preds_flat - trues_flat) ** 2)\n",
        "    mae = np.mean(np.abs(preds_flat - trues_flat))\n",
        "    r2_val = r2_score(trues_flat[:, 0], preds_flat[:, 0])\n",
        "    r2_aro = r2_score(trues_flat[:, 1], preds_flat[:, 1])\n",
        "    ccc_val = concordance_correlation_coefficient(trues_flat[:, 0], preds_flat[:, 0])\n",
        "    ccc_aro = concordance_correlation_coefficient(trues_flat[:, 1], preds_flat[:, 1])\n",
        "\n",
        "    print(\"\\n== 전체 Test Set 결과 ==\")\n",
        "    print(f\"  MSE: {mse:.4f}, MAE: {mae:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "aDoijVc4o37M",
        "outputId": "166d29ab-fd6c-475a-9a99-2ac8d86c5582"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "곡 단위 테스트 데이터 예측을 시작합니다...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Given groups=1, weight of size [16, 1, 3, 3], expected input[1, 10, 128, 60] to have 1 channels, but got 10 channels instead",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-26-1778841750.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0mpreds_padded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-16-3609024220.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0;31m# x: [B,1,128,60]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0mfeat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m          \u001b[0;31m# → [B,60,2]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m         \u001b[0mfeat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m   \u001b[0;31m# → [B,2,60,1]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m         \u001b[0mfeat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchannel_mapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeat\u001b[0m\u001b[0;34m)\u001b[0m           \u001b[0;31m# → [B,d_model,60,1]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-16-3609024220.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0;31m# x: [B,1,128,60]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblock1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m   \u001b[0;31m# → [B,16,64,60]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m   \u001b[0;31m# → [B,32,32,60]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblock3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m   \u001b[0;31m# → [B,64,16,60]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    248\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    552\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 554\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    555\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    547\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroups\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m             )\n\u001b[0;32m--> 549\u001b[0;31m         return F.conv2d(\n\u001b[0m\u001b[1;32m    550\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdilation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroups\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m         )\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Given groups=1, weight of size [16, 1, 3, 3], expected input[1, 10, 128, 60] to have 1 channels, but got 10 channels instead"
          ]
        }
      ]
    }
  ]
}